configfile: "config.yaml"

###### paths ###############
DATA = config["general_paths"]["data"]
SRC = config["general_paths"]["src"]
CONDA_ENVS = config["general_paths"]["conda_envs"]
METADATA = config["paths"]["metadata"]
DATABASE = config["paths"]["database"]
GENE_SETS_DIR = config["paths"]["gene_sets_dir"]
SPLSDA_ANALYSIS_DIR = config["paths"]["splsda_analysis"]
GO_TRANSFERS = config["paths"]["go_transfers"]
MOTIF_ANALYSIS_DIR = config["paths"]["motif_analysis_dir"]
TS_GAINS_LOSSES_DIR = config["paths"]["ts_gains_and_losses_dir"]

######## tools ############
RSCRIPT = config["tools"]["rscript"]

###### variables ###########
MY_VERSION = config["variables"]["my_version"]
MY_CATEGORY = config["variables"]["my_category"]
ALL_SPECIES = config["variables"]["all_species"]
ALL_SPECIES_GAINS = config["variables"]["all_species_gains"]
BILATERIA = ALL_SPECIES
VERTEBRATA = config["variables"]["vertebrata"]
INSECTA = config["variables"]["insecta"]
OUTGROUPS = config["variables"]["outgroups"]
DEUTEROSTOMA = config["variables"]["deuterostoma"]
PROTOSTOMA = config["variables"]["protostoma"]
CLADES = config["variables"]["clades"]

CLADE_SPECIES_DICT = {}
CLADE_SPECIES_DICT["Vertebrata"] = VERTEBRATA
CLADE_SPECIES_DICT["Insecta"] = INSECTA
CLADE_SPECIES_DICT["Bilateria"] = BILATERIA

CATEGORIES = config["variables"]["categories"]
EVO_TYPES = config["variables"]["evo_types"]
EXPR_TYPES = config["variables"]["expr_types"]
ALL_TISSUES = config["variables"]["all_tissues"]
MOTIF_CATEGORIES = config["variables"]["motif_categories"]
NODE_SPECIES_DICT = config["variables"]["node_species_dict"]
ALL_NODES = config["variables"]["all_nodes"]
NODE_SUBNODES_DICT = config["variables"]["node_subnodes_dict"]
SPECIES_SUBCLADES_DICT = config["variables"]["species_subclades_dict"]

###### targets ##########

####### rules ############
rule all:	
	input:
	
#######################################
###### ANCESTRAL BILATERIAN INPUTS ####
#######################################

rule generate_ancestral_bilaterian_sets:
	input:
		BH_orthogroups = GENE_SETS_DIR+"/{my_version}/STRICT/Bilateria/conserved/Bilateria_conserved-reclustered_orthogroups-BH_genes.txt",
		OG_IDs = SPLSDA_ANALYSIS_DIR+"/{my_version}/STRICT/Bilateria/conserved/loadings/metasamples_median_expr/splsda_zscore_comb/{tissue}_splsda-zscore_loadings_orthogroups-GO_input.txt"
	output:
		MOTIF_ANALYSIS_DIR+"/{my_version}/gene_sets_inputs/Bilateria_ancestral/{tissue}/{species}-{tissue}-Bilateria_ancestral_geneIDs.txt"
	shell:
		"""
		cat {input.BH_orthogroups} | grep {wildcards.species} | filter_1col 1 {input.OG_IDs} | cut -f3 | sort | uniq > {output}
		"""


#######################################
###### CLADE-SPECIFIC INPUTS ##########
#######################################

rule generate_clade_specific_sets:
	input:
		BH_orthogroups = GENE_SETS_DIR+"/{my_version}/STRICT/Bilateria/conserved/Bilateria_conserved-reclustered_orthogroups-BH_genes.txt",
		OG_IDs = SPLSDA_ANALYSIS_DIR+"/{my_version}/STRICT/Bilateria/conserved/loadings_clade_tissue/metasamples_median_expr/{tissue}/splsda_zscore_comb/{clade}_{tissue}_splsda-zscore_loadings_orthogroups-GO_input.txt"
	output:
		MOTIF_ANALYSIS_DIR+"/{my_version}/gene_sets_inputs/{clade}_specific/{tissue}/{species}-{tissue}-{clade}_specific_geneIDs.txt"
	shell:
		"""
		cat {input.BH_orthogroups} | grep {wildcards.species} | filter_1col 1 {input.OG_IDs} | cut -f3 | sort | uniq > {output}
		"""

#######################################
###### BACKGROUNDS ####################
#######################################

#This is the BH background
rule generate_backgrounds:
	input:
		GENE_SETS_DIR+"/{my_version}/STRICT/Bilateria/conserved/Bilateria_conserved-reclustered_orthogroups-BH_genes.txt"
	output:
		MOTIF_ANALYSIS_DIR+"/{my_version}/backgrounds/{species}-all_bilaterian_conserved_BH_genes.txt"
	shell:
		"""
		cat {input} | grep {wildcards.species} | cut -f3 | sort | uniq > {output}
		"""

#I am now getting all the bilaterian conserved genes for each species which were not included in the BH background.
rule generate_complementary_background:
	input:
		bilaterian_conserved_orthogroups = GENE_SETS_DIR+"/{my_version}/STRICT/Bilateria/conserved/Bilateria_conserved_orthogroups-EXPR_genes.txt",
		BH_orthogroups = GENE_SETS_DIR+"/{my_version}/STRICT/Bilateria/conserved/Bilateria_conserved-reclustered_orthogroups-BH_genes.txt"
	output:
		MOTIF_ANALYSIS_DIR+"/{my_version}/backgrounds_complementary/{species}-all_bilaterian_conserved_nonBH_genes.txt"
	shell:
		"""
		cat {input.bilaterian_conserved_orthogroups} | grep {wildcards.species} | cut -f3 | sort | uniq | filter_1col -v 1 \
		<(cat {input.BH_orthogroups} | grep {wildcards.species} | cut -f3) > {output}
		"""

#######################################
###### GAINS ALL NODES ################
#######################################
#rule generate_all_gains_input:
#	input:
#		gains = TS_GAINS_LOSSES_DIR+"/"+MY_CATEGORY+"/{my_version}/inferences/Bilateria_conserved_orthogroups-All_genes-{tissue}_inferred_gains.tab",
#		orthogroups = TS_GAINS_LOSSES_DIR+"/"+MY_CATEGORY+"/{my_version}/Bilateria_conserved_orthogroups-All_genes-{tissue}_specific_OGs.tab"
#	output:
#		MOTIF_ANALYSIS_DIR+"/{my_version}/all_ts_gains/{clade}/{tissue}/{clade}-{tissue}_specific_geneIDs.txt"
#	params:
#		clade_species = lambda wildcards : NODE_SPECIES_DICT[wildcards.clade],
#		output_dir = MOTIF_ANALYSIS_DIR+"/{my_version}/all_ts_gains/{clade}/{tissue}/",
#		output_suffix = "_specific_geneIDs.txt"
#	run:
#
#		import pandas as pd
#
#		gains_df = pd.read_table(str(input.gains), sep="\t", index_col=False, header=0) #Header: [OG_ID, TS_gain, Category]
#		orthogroups_df = pd.read_table(str(input.orthogroups), sep="\t", index_col=False, header=None, names=["OG_ID", "Species", "GeneID", "Tau", "Tissue", "Paralog_Tissue", "Expr_cutoff"])
#		#Isolate all the orthogroups with gains in the selected clade/species
#		selected_gains_OGs = list(gains_df.loc[gains_df["TS_gain"]==str(wildcards.clade)]["OG_ID"])
#		#Filter the orthogroups df for the selected gains orthogroups and for the species in those clades	
#		filtered_orthogroups_df = orthogroups_df.loc[(orthogroups_df["OG_ID"].isin(selected_gains_OGs)) & (orthogroups_df["Species"].isin(params.clade_species))]
#		#Save all geneIDs together (this makes my life easier with the output file definition)
#		filtered_orthogroups_df.to_csv(str(output), sep="\t", index=False, header=False, na_rep="NA")
#		#Save a separate file for each of the species
#		for my_species in params.clade_species:
#		  output_file = str(params.output_dir) + "/" + my_species + "-" + str(wildcards.tissue) + "-" + str(wildcards.clade) + str(params.output_suffix)
#		  species_final_orthogroups_df = filtered_orthogroups_df.loc[filtered_orthogroups_df["Species"]==my_species,["GeneID"]]
#		  species_final_orthogroups_df.to_csv(output_file, sep="\t", index=False, header=False, na_rep="NA")
#
#
########################################
####### COLLAPSED GAINS ################
########################################
#
##Collapse by species and by tissue all the tissue-specificity gains from Vertebrata/Insecta on.
#rule generate_collapsed_gains_input:
#	input:
#		gains = TS_GAINS_LOSSES_DIR+"/"+MY_CATEGORY+"/{my_version}/inferences/Bilateria_conserved_orthogroups-All_genes-{tissue}_inferred_gains.tab",
#		losses = TS_GAINS_LOSSES_DIR+"/"+MY_CATEGORY+"/{my_version}/inferences/Bilateria_conserved_orthogroups-All_genes-{tissue}_inferred_losses.tab",
#		orthogroups = TS_GAINS_LOSSES_DIR+"/"+MY_CATEGORY+"/{my_version}/Bilateria_conserved_orthogroups-All_genes-{tissue}_specific_OGs.tab"
#	output:
#		MOTIF_ANALYSIS_DIR+"/{my_version}/all_ts_gains/{clade}_collapsed/{tissue}/{clade}-{tissue}_specific_geneIDs.txt"
#	params:
#		clade_species = lambda wildcards : NODE_SPECIES_DICT[wildcards.clade],
#		subclades = lambda wildcards : NODE_SUBNODES_DICT[wildcards.clade],
#		species_subclades_dict = SPECIES_SUBCLADES_DICT,
#		output_dir = MOTIF_ANALYSIS_DIR+"/{my_version}/all_ts_gains/{clade}_collapsed/{tissue}/",
#		output_suffix = "_specific_geneIDs.txt"
#	run:
#		import pandas as pd
#
#		nodes_and_species = list(params.clade_species) + list(params.subclades)
#
#		gains_df = pd.read_table(str(input.gains), sep="\t", index_col=False, header=0) #Header: [OG_ID, TS_gain, Category]
#		losses_df = pd.read_table(str(input.losses), sep="\t", index_col=False, header=0) #Header: [OG_ID, TS_losses, Category]
#		orthogroups_df = pd.read_table(str(input.orthogroups), sep="\t", index_col=False, header=None, names=["OG_ID", "Species", "GeneID", "Tau", "Tissue", "Paralog_Tissue", "Expr_cutoff"])
#		#Cycle on the clades and single species, and select the orthogroups with gains
#		selected_gains_OGs = list(gains_df.loc[gains_df["TS_gain"].isin(nodes_and_species)]["OG_ID"])
#		#Filter the ortthogroups df for the selected gains orthogroups and for the species in those clade
#		filtered_orthogroups_df = orthogroups_df.loc[(orthogroups_df["OG_ID"].isin(selected_gains_OGs)) & (orthogroups_df["Species"].isin(params.clade_species))]
#		#Save all geneIDs together (this makes my life easier with the output file definition)
#		filtered_orthogroups_df.to_csv(str(output), sep="\t", index=False, header=False, na_rep="NA")
#
#		for my_species in params.clade_species:
#		  #Define the species subnodes
#		  species_subnodes = params.species_subclades_dict[my_species]
#		  #Select the gains where that species is included
#		  selected_gains_OGs = list(gains_df.loc[gains_df["TS_gain"].isin(species_subnodes + [my_species])]["OG_ID"])
#		  selected_losses_OGs = list(losses_df.loc[losses_df["TS_losses"].isin(species_subnodes + [my_species])]["OG_ID"])
#		  final_selected_gains_OGs = [gain for gain in selected_gains_OGs if gain not in selected_losses_OGs]
#		  #Filter the orthogroups dataframe for the gains orthogroups and that species
#		  species_final_orthogroups_df = orthogroups_df.loc[((orthogroups_df["OG_ID"].isin(final_selected_gains_OGs)) & (orthogroups_df["Species"]==my_species)),["GeneID"]] 
#		  #Remove from the list the orthogroups with losses
#		  output_file = str(params.output_dir) + "/" + my_species + "-" + str(wildcards.tissue) + "-" + str(wildcards.clade) + str(params.output_suffix)
#		  species_final_orthogroups_df.to_csv(output_file, sep="\t", index=False, header=False, na_rep="NA")
#
########################################
####### NON-TS CONTROL GROUPS ##########
########################################
#
#rule generate_nonTS_control_groups:
#	input:
#		BH_orthogroups = GENE_SETS_DIR+"/{my_version}/STRICT/Bilateria/conserved/Bilateria_conserved-reclustered_orthogroups-BH_genes.txt",
#		taus = TS_GAINS_LOSSES_DIR+"/"+MY_CATEGORY+"/{my_version}/Bilateria_conserved_orthogroups-All_genes-associated_tissues-unfiltered.tab" 
#	output:
#		low_tau = MOTIF_ANALYSIS_DIR+"/{my_version}/nonTS_controls/low_tau/{species}-low_taus_geneID.txt",
#		medium_tau = MOTIF_ANALYSIS_DIR+"/{my_version}/nonTS_controls/medium_tau/{species}-medium_taus_geneID.txt"
#	shell:
#		"""
#		cat {input.BH_orthogroups} | grep {wildcards.species} | cut -f3 | sort | uniq | filter_1col 1 \
#		<(cat {input.taus} | awk '$4<=0.15' | cut -f3) > {output.low_tau}; \
#		cat {input.BH_orthogroups} | grep {wildcards.species} | cut -f3 | sort | uniq | filter_1col 1 \
#		<(cat {input.taus} | awk '$4>0.15 && $4<=0.45' | cut -f3) > {output.medium_tau}; \ 
#		"""
#
##############################################
####### ALL INFO TABLE #######################
##############################################
#
#rule generate_all_info_table:
#	input:
#		motif_info = MOTIF_ANALYSIS_DIR+"/{my_version}/pre_data4_OG-FM.tab",
#		gains_info = expand(TS_GAINS_LOSSES_DIR+"/"+MY_CATEGORY+"/{{my_version}}/inferences/Bilateria_conserved_orthogroups-All_genes-{tissue}_inferred_gains.tab", tissue=ALL_TISSUES)
#	output:
#		MOTIF_ANALYSIS_DIR+"/{my_version}/pre_data4_OG-tissue_specificity_gains_info-FM.tab"		
#	params:
#		all_tissues = ALL_TISSUES,
#		all_nodes = ALL_NODES,
#		gains_file_prefix = "Bilateria_conserved_orthogroups-All_genes-",
#		gains_file_suffix = "_inferred_gains.tab"
#	run:
#
#		import pandas as pd
#		import re
#		import numpy as np
#
#		input_df = pd.read_table(input.motif_info, sep="\t", index_col=False, header=0)
#		#Cycle on the gains info files and unify them
#		all_gains_df = pd.DataFrame()
#		#gain_info_files = [file for file in os.listdir(".") if "Bilateria_conserved_orthogroups-All_genes-" in file]
#		for my_file in list(input.gains_info):
#		  tissue = re.sub(params.gains_file_suffix, "", re.sub(".*"+params.gains_file_prefix, "", my_file))
#		  gains_df = pd.read_table(my_file, sep="\t", header=0, index_col=False)
#		  gains_df["Tissue"] = tissue
#		  all_gains_df = pd.concat([all_gains_df, gains_df])
#		#Collapse entries by OG and Node
#		all_gains_df = all_gains_df.drop("Category", axis=1)
#		collapsed_gains_df = all_gains_df.groupby(["OG_ID", "TS_gain"])['Tissue'].apply(list).reset_index(name='Tissue_list')	
#		collapsed_gains_df["Tissue"] = collapsed_gains_df["Tissue_list"].apply(lambda x: ';'.join(map(str, x)))
#		collapsed_gains_df = collapsed_gains_df.drop("Tissue_list", axis=1)
#		#Transform to wide format
#		wide_collapsed_gains_df = pd.pivot(collapsed_gains_df, index="OG_ID", columns="TS_gain", values="Tissue")
#		wide_collapsed_gains_df = wide_collapsed_gains_df.astype(object).replace(np.nan, "None") #Transform Nan to None
#		#Reorder columns based on nodes
#		reordered_wide_collapsed_gains_df = wide_collapsed_gains_df[ALL_NODES]
#		#Merge dataframes
#		final_df = input_df.merge(reordered_wide_collapsed_gains_df, how="left", left_on="Filtered_OGs", right_index=True)
#		final_df.to_csv(str(output), sep="\t", index=False, header=True, na_rep="NA")
#
#
#rule add_bilaterian_core:
#	input:
#		template = MOTIF_ANALYSIS_DIR+"/{my_version}/pre_data4_OG-tissue_specificity_gains_info-FM.tab",
#		bilaterian_core = expand(SPLSDA_ANALYSIS_DIR+"/{{my_version}}/STRICT/Bilateria/conserved/loadings/metasamples_median_expr/splsda_zscore_comb/{tissue}_splsda-zscore_loadings_orthogroups-GO_input.txt", tissue=ALL_TISSUES)
#	output:
#		MOTIF_ANALYSIS_DIR+"/{my_version}/pre_data4_OG-tissue_specificity_gains_info-plus_ancestral_cores-FM.tab"
#	params:
#		bilaterian_core_suffix = "_splsda-zscore_loadings_orthogroups-GO_input.txt"
#	run:
#
#		import pandas as pd
#		import re
#		import numpy as np
#
#		#import data
#		input_df = pd.read_table(input.template, sep="\t", index_col=False, header=0)
#		#Cycle on bilaterian core files, and create a dictionary with key="OG_ID", value="None"
#		all_ancestral_df = pd.DataFrame()
#		for my_file in list(input.bilaterian_core):
#		  my_tissue = re.sub(params.bilaterian_core_suffix, "", re.sub(".*/", "", my_file))
#		  ancestral_df = pd.read_table(my_file, sep="\t", index_col=False, header=None, names=["OG_ID"])
#		  ancestral_df["Tissue"] = my_tissue
#		  all_ancestral_df = pd.concat([all_ancestral_df, ancestral_df])
#		#Get the dictionary
#		ancestral_OG_tissue_dict = pd.Series(all_ancestral_df.Tissue.values, index=all_ancestral_df.OG_ID).to_dict()
#		#Add information of input_df
#		input_df["Bilaterian_core"] = input_df["Filtered_OGs"].map(ancestral_OG_tissue_dict).fillna("None")
#		#Save to output
#		input_df.to_csv(str(output), sep="\t", index=False, header=True, na_rep="NA")
#
#
#rule add_vertebrata_and_insect_specific:
#	input:
#		template = MOTIF_ANALYSIS_DIR+"/{my_version}/pre_data4_OG-tissue_specificity_gains_info-plus_ancestral_cores-FM.tab",
#		vertebrata = expand(SPLSDA_ANALYSIS_DIR+"/{{my_version}}/STRICT/Bilateria/conserved/loadings_clade_tissue/metasamples_median_expr/{tissue}/splsda_zscore_comb/Vertebrata_{tissue}_splsda-zscore_loadings_orthogroups-GO_input.txt", tissue=ALL_TISSUES),
#		insecta = expand(SPLSDA_ANALYSIS_DIR+"/{{my_version}}/STRICT/Bilateria/conserved/loadings_clade_tissue/metasamples_median_expr/{tissue}/splsda_zscore_comb/Insecta_{tissue}_splsda-zscore_loadings_orthogroups-GO_input.txt", tissue=ALL_TISSUES)
#	output:
#		MOTIF_ANALYSIS_DIR+"/{my_version}/pre_data4_OG-tissue_specificity_gains_info-plus_ancestral_cores-plus_verts_and_insects-FM.tab"
#	params:
#		file_suffix = "_splsda-zscore_loadings_orthogroups-GO_input.txt"
#	run:
#
#		import pandas as pd
#		import re
#		import numpy as np
#
#		#import data
#		input_df = pd.read_table(input.template, sep="\t", index_col=False, header=0)
#		#Cycle on the vertebrata files, and create a dictionary with key="OG_ID", value="None"
#		all_vertebrata_df = pd.DataFrame()
#		for my_file in list(input.vertebrata):
#		  my_tissue = re.sub(params.file_suffix, "", re.sub(".*Vertebrata_", "", my_file))
#		  vertebrata_df = pd.read_table(my_file, sep="\t", index_col=False, header=None, names=["OG_ID"])
#		  vertebrata_df["Tissue"] = my_tissue
#		  all_vertebrata_df = pd.concat([all_vertebrata_df, vertebrata_df])
#		#Get the dictionary
#		vertebrata_OG_tissue_dict = pd.Series(all_vertebrata_df.Tissue.values, index=all_vertebrata_df.OG_ID).to_dict()
#		#Add information of input_df
#		input_df["Vertebrata_specific"] = input_df["Filtered_OGs"].map(vertebrata_OG_tissue_dict).fillna("None")
#
#		#Cycle on the insecta files, and create a dictionary with key="OG_ID", value="None"
#		all_insecta_df = pd.DataFrame()
#		for my_file in list(input.insecta):
#		  my_tissue = re.sub(params.file_suffix, "", re.sub(".*Insecta_", "", my_file))
#		  insecta_df = pd.read_table(my_file, sep="\t", index_col=False, header=None, names=["OG_ID"])
#		  insecta_df["Tissue"] = my_tissue
#		  all_insecta_df = pd.concat([all_insecta_df, insecta_df])
#		#Get the dictionary
#		insecta_OG_tissue_dict = pd.Series(all_insecta_df.Tissue.values, index=all_insecta_df.OG_ID).to_dict()
#		#Add information of input_df
#		input_df["Insecta_specific"] = input_df["Filtered_OGs"].map(insecta_OG_tissue_dict).fillna("None")
#
#		#Save to output
#		input_df.to_csv(str(output), sep="\t", index=False, header=True, na_rep="NA")
