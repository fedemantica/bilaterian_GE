########## config file #########
configfile: "config.yaml"

########## paths ###############
CONDA_ENVS = config["general_paths"]["conda_envs"]
BROCCOLI = config["paths"]["broccoli"]
DATABASE = config["paths"]["database"]
GENOME_DIR = config["paths"]["genome_dir"]
GTF_REF_DIR = config["paths"]["gtf_ref_dir"]
EXINT_REF_DIR = config["paths"]["exint_ref_dir"]

########## variables ###########
ALL_SPECIES = config["variables"]["all_species"]
INVERTEBRATE_SPECIES = config["variables"]["invertebrate_species"]
MY_VERSION = config["variables"]["my_version"]
GENE_NUM = config["variables"]["gene_num"]
SEQSIM_CUTOFF = config["variables"]["seqsim_cutoff"]
HUMAN_MATCH_CUTOFF = config["variables"]["human_match_cutoff"]

ALL_CLUSTERS_PART = list(range(1,5)) #This refers to the old chimeric genes pipeline. Probably to be removed.

#generate list of chimeric genes
#This still will not work with a single command from the very beginning. I need to find an alternative.
import os
import re
import pandas as pd
chimeric_protein_file = BROCCOLI+"/"+MY_VERSION+"/chimeric_proteins/chimeric_orthogroups.tab"
if os.path.isfile(chimeric_protein_file):
  chimeric_genes_df = pd.read_table(chimeric_protein_file, sep="\t", header=0, index_col=False)
  chimeric_genes = list(set(list(chimeric_genes_df[chimeric_genes_df["chimeric_label"]=="chimeric"]["geneID"]))) #remove duplicates
  n = 50 #generate batches of 50 chimeric genes
  chimeric_genes_batches = [chimeric_genes[i:i+n] for i in range(0, len(chimeric_genes), n)]
  CHIMERIC_GENES = [[",".join(element)] for element in chimeric_genes_batches]
  CHIMERIC_GENES_BATCHES = list(range(len(CHIMERIC_GENES))) #number of batches, to use as index

OVERLAP_STRINGENCY = config["variables"]["overlap_stringency"]

######### tools ################
BROCCOLI_MAIN = config["tools"]["broccoli_main"] #We are using v1.2 of Broccoli
GET_EXINT_FASTA = config["tools"]["get_exint_fasta"]
COMPUTE_PROT_LEN = config["tools"]["compute_prot_len"]
MY_MAFFT = config["tools"]["mafft"]
COMPUTE_PROT_OVERLAP = config["tools"]["compute_prot_overlap"]
COMPUTE_SIM_SCORE = config["tools"]["compute_sim_score"]
TARGET_MATCH_PORTION = config["tools"]["target_matched_portion"]
GET_CHIMERIC_CLUSTERS = config["tools"]["get_chimeric_clusters"]
SPLIT_CLUSTERS = config["tools"]["split_clusters"]
GET_SIM_SCORES_CHIMERIC = config["tools"]["get_sim_scores_chimeric"]
GET_LONGEST_ALN = config["tools"]["get_longest_aln"]
GET_EXON_POS_ALN = config["tools"]["get_exon_pos_aln"]
GET_FIRST_LAST_EX_ALN = config["tools"]["get_first_last_ex_aln"]
GET_EXCOORDS = config["tools"]["get_excoords"]
GET_EX_PATH = config["tools"]["get_ex_path"]
GET_AA_POSITIONS = config["tools"]["get_aa_position"]
ALIGN_CHIMERIC_OG = config["tools"]["align_chimeric_OG"]
GET_CHIMERIC_ALIGNED_REGION = config["tools"]["get_chimeric_aligned_region"]

########## targets #############
RUN_BROCCOLI=expand("{path}/{my_version}/dir_step4/orthologous_pairs.txt", path=BROCCOLI, my_version=MY_VERSION)
PARSED_ORTHOGROUPS=expand("{path}/{my_version}/parsed_orthogroups.txt", path=BROCCOLI, my_version=MY_VERSION)
SELECTED_BROKEN_GENES=expand("{path}/{my_version}/broken_genes/{species}-selected_broken_genes.tab", path=BROCCOLI, my_version=MY_VERSION, species=INVERTEBRATE_SPECIES)

#Chimeric genes: the difference here is that it runs for all species
CHIMERIC_CLUSTERS = expand("{path}/{my_version}/chimeric_proteins/splitted_clusters/part_1_clusters.txt", path=BROCCOLI, my_version=MY_VERSION)
CHIMERIC_PROT_SIM_SCORES = expand("{path}/{my_version}/chimeric_proteins/sim_scores/scores_part_{part}.txt", path=BROCCOLI, my_version=MY_VERSION, part=ALL_CLUSTERS_PART)
LONGEST_FRAGMENT = expand("{path}/{my_version}/chimeric_proteins/Longest_aln_chimeric_prots.tab", path=BROCCOLI, my_version=MY_VERSION)
COMBINED_EX_POS_INFO = expand("{path}/{my_version}/chimeric_proteins/Combines_exons_pos_info.tab", path=BROCCOLI, my_version=MY_VERSION)
CHIMERIC_OG = expand("{path}/{my_version}/chimeric_proteins/chimeric_orthogroups.tab", path=BROCCOLI, my_version=MY_VERSION)
#MULTIPLE_ALN = expand("{path}/{my_version}/chimeric_proteins/multiple_aln/{chimeric_gene}-multiple_aln", path=BROCCOLI, my_version=MY_VERSION, chimeric_gene=CHIMERIC_GENES)
MULTIPLE_ALN = expand("{path}/{my_version}/chimeric_proteins/multiple_aln/batch_{batch_index}.log", path=BROCCOLI, my_version=MY_VERSION, batch_index=CHIMERIC_GENES_BATCHES)
ALIGNED_FRAGMENT_INFO = expand("{path}/{my_version}/chimeric_proteins/aligned_fragments_info.tab", path=BROCCOLI, my_version=MY_VERSION)

######### rules ################

rule all:
	input:
		RUN_BROCCOLI,
		PARSED_ORTHOGROUPS, 
		SELECTED_BROKEN_GENES,
		CHIMERIC_CLUSTERS,
		CHIMERIC_PROT_SIM_SCORES,
		LONGEST_FRAGMENT,
		COMBINED_EX_POS_INFO,
		CHIMERIC_OG,
		MULTIPLE_ALN,
		ALIGNED_FRAGMENT_INFO

###############################################
######## GET REF_PROTEINS FASTA  ##############
###############################################

#Get a fasta file containing only reference proteins
rule ref_proteins_exint:
	input:
		gtf = GTF_REF_DIR+"/{species}_annot-B.gtf",
		genome = GENOME_DIR+"/{species}_gDNA.fasta"
	output:
		EXINT_REF_DIR+"/{species}_ref_exint.fasta"
	shell:
		"""
		perl {GET_EXINT_FASTA} -GTF {input.gtf} -G {input.genome} -out {output}
		"""

#Generate links in the fasta input directory for the current version
rule link_to_exint:
	input:
		expand("{path}/{species}_ref_exint.fasta", path=EXINT_REF_DIR, species=ALL_SPECIES)
	output:
		expand("{path}/{{my_version}}/fastas/{species}_ref_exint.fasta", path=BROCCOLI, species=ALL_SPECIES)
	params:
		output_dir = BROCCOLI+"/{my_version}/fastas" 
	shell:
		"""
		cd {params.output_dir}; for file in $(echo {input}); do ln -s $file ./; done
		"""

###############################################
########### RUN BROCCOLI  #####################
###############################################

rule run_broccoli_20_species:
	input:
		expand("{path}/{my_version}/fastas/{species}_ref_exint.fasta", path=BROCCOLI, my_version=MY_VERSION, species=ALL_SPECIES)
	output:
		BROCCOLI+"/{my_version}/dir_step3/orthologous_groups.txt",
		BROCCOLI+"/{my_version}/dir_step4/orthologous_pairs.txt",
		BROCCOLI+"/{my_version}/dir_step3/chimeric_proteins.txt"
	params:
		working_dir = BROCCOLI+"/{my_version}",
		fasta_dir = BROCCOLI+"/{my_version}/fastas"
	conda:
		CONDA_ENVS+"/broccoli_1.2.yml"
	shell:		
		"""
		cd {params.working_dir}; \
		python {BROCCOLI_MAIN} -dir {params.fasta_dir} -threads 16
		"""

# generate a stupid file with geneID-species for all my species of interest
# the file suffix has to match *_ref_exint.fasta
rule geneID_species_file:
	input:
		expand("{path}/{{my_version}}/fastas/{species}_ref_exint.fasta", path=BROCCOLI, species=ALL_SPECIES)
	output:
		BROCCOLI+"/{my_version}/geneID_species_dict.tab"
	params:
		input_dir = BROCCOLI+"/{my_version}/fastas"
	shell:
		"""
		for file in $(ls {input}); do \
			my_species=$(basename $file | sed 's/_ref_exint.fasta//'); \
			cat $file | grep ">" | sed 's/>//; s/.*|//' \
			| awk -v OFS="\t" -v sp=$my_species '{{print $1,sp}}'; \
		done > {output}
		"""

#An NA will be added when the gene does not have a name
rule parse_orthogroups:
	input:
		orthogroups = BROCCOLI+"/{my_version}/dir_step3/orthologous_groups.txt", 
		gene_names = expand("{path}/gene_names/{species}.ID.names.txt", path=DATABASE, species=ALL_SPECIES),
		gene_species_dict = BROCCOLI+"/{my_version}/geneID_species_dict.tab"
	output:
		BROCCOLI+"/{my_version}/parsed_orthogroups.txt"
	run:
		import pandas as pd
		import re
		import ntpath

		gene_ID_gene_name_dict = {} #build dictionary with {gene_ID : gene_name} for all species
		#build a dictionary with {gene_id : species} for all species
		gene_ID_species_df = pd.read_table(str(input.gene_species_dict), sep="\t", header=None, names=["GeneID", "Species"])
		gene_ID_species_dict = pd.Series(gene_ID_species_df.Species.values, index=gene_ID_species_df.GeneID).to_dict()
		for my_file in input.gene_names:
		  my_species = re.sub(".ID.names.txt", "", ntpath.basename(my_file))
		  gene_names_df = pd.read_table(str(my_file), header=None, sep="\t", names=["GeneID", "GeneName"])
		  gene_ID_gene_name_dict.update(pd.Series(gene_names_df.GeneName.values, index=gene_names_df.GeneID).to_dict())
		
		#read df with orthogroups
		my_df = pd.read_table(str(input.orthogroups), sep="\t", header=0)
		my_df["ClusterID"] = [re.sub(".*_", "GF_"+str("0"*(9-len(element))), element) for element in list(my_df["#OG_name"])]
		grouped_df = my_df.groupby("ClusterID")
		final_df = pd.DataFrame(columns=["ClusterID", "GeneID"])

		for name, group in grouped_df:
		  genes_list = [re.sub(".*\|", "", element) for element in list(group["protein_names"])[0].split(" ")]
		  my_group_df = pd.DataFrame({"ClusterID" : name, "GeneID" : genes_list})
		  final_df = pd.concat([final_df, my_group_df])

		final_df["Species"] = final_df["GeneID"].map(gene_ID_species_dict) #add species
		final_df["GeneName"] = final_df["GeneID"].map(gene_ID_gene_name_dict) #add gene name
		final_df = final_df[["ClusterID", "Species", "GeneID", "GeneName"]]#reorder columns
		final_df.to_csv(str(output), sep="\t", header=False, index=False, na_rep="NA")


###############################################
########### BROKEN GENES  #####################
###############################################

#generate a file with chr and strand info for each gene.
#19/03/21: I should do this starting from the reference proteins.
rule chr_strand_info_by_gene:
	input:
		GTF_REF_DIR+"/{species}_annot-B.gtf"	
	output:
		DATABASE+"/gene_extra_info/{species}_chr_strand.tab"
	shell:
		"""
		cat {input} | grep "gene_id" | cut -f1,7,9 | tr ";" "\t" | cut -f1-3 \
		| sed 's/gene_id //; s/"//g' \
		| awk -v OFS="\t" '{{print $3,$1,$2}}' | sort | uniq > {output}
		"""

rule start_stop_info_by_gene:
	input:
		GTF_REF_DIR+"/{species}_annot-B.gtf"
	output:
		DATABASE+"/gene_extra_info/{species}_start_stop.tab"
	run:
		import pandas as pd

		my_gtf_df = pd.read_table(str(input), sep="\t", names=["chr", "source", "feature", "start", "stop", "score", "strand", "phase", "attributes"])
		intermediate_gene_list = [re.sub(";.*", "", element) for element in list(my_gtf_df["attributes"])]
		my_gtf_df["geneID"] = pd.Series([re.sub(" ", "", re.sub("gene_id ", "", re.sub('"', '', element))) for element in intermediate_gene_list])
		my_filtered_gtf = my_gtf_df.loc[my_gtf_df.feature=="exon"] #filter only for exons
		my_filtered_gtf = my_gtf_df.loc[:,["geneID","chr","start","stop"]]
		#group by geneID and select lower start and higher stop (just looking at DNA, so here is actually the same independently from the strand)
		final_df = pd.DataFrame(columns=list(my_filtered_gtf.columns.values))
		my_grouped_df = my_filtered_gtf.groupby("geneID")
		for name, group in my_grouped_df:
		  my_chr = list(group["chr"])[0]
		  my_start = min(list(group["start"]))
		  my_stop = max(list(group["stop"]))
		  group_df = pd.DataFrame({"geneID" : [name], "chr" : [my_chr], "start" : [my_start], "stop" : [my_stop]})
		  final_df = pd.concat([final_df, group_df])
		#write to file
		final_df.to_csv(str(output), sep="\t", index=False, header=False)


##### Add a rule to get the protein lenght.
#protein lenght: get a file with the geneID and the length of the all the proteins in fasta file.
#find the right input to add in here.

#Why was I not using a conda environment here?
#Because snakemake does not allow you to use conda environments with "run" chuncks.
#I could create a script and call it from the shell, but I don't really love the idea.
rule protein_length:
	input:
		EXINT_REF_DIR+"/{species}_ref_exint.fasta"
	output:
		DATABASE+"/gene_extra_info/{species}_ref_proteins_lengths"
	conda:
		CONDA_ENVS+"/broccoli_1.2.yml"
	shell:
		"""
		python {COMPUTE_PROT_LEN} -i {input} -o {output}
		"""

###############################################
############### STEPS ######################### 
###############################################

#for all invertebrates, isolate all the clusters with 2 or more genes from the same species
rule isolate_potential_broken:
	input:
		BROCCOLI+"/{my_version}/parsed_orthogroups.txt"
	output:
		BROCCOLI+"/{my_version}/broken_genes/{species}/{species}-potentially_broken-step1.tab"
	shell:
		"""
		cat {input} | awk '$1!="" && $2=="{wildcards.species}"' \
		| filter_1col 1 <(cat {input} | awk '$2=="{wildcards.species}"' \
		| cut -f1 | sort | uniq -c \
		| sed 's/^[ \t]*//; s/ /\t/' | awk '$1>=2' | cut -f2) > {output}
		"""

#select only those clusters where the genes are on the same chr and strand
rule filter_by_chr_strand:
	input:
		clusters = BROCCOLI+"/{my_version}/broken_genes/{species}/{species}-potentially_broken-step1.tab",
		extra_info = DATABASE+"/gene_extra_info/{species}_chr_strand.tab"
	output:
		BROCCOLI+"/{my_version}/broken_genes/{species}/{species}-potentially_broken-step2.tab"
	run:
		import pandas as pd
		
		my_clusters_df = pd.read_table(str(input.clusters), sep="\t", header=None, names=["clusterID", "species", "geneID", "gene_name"])
		my_extra_info = pd.read_table(str(input.extra_info), sep="\t", header=None, names=["geneID", "chr", "strand"])
		#create dictionaries for chr and strand
		my_chr_dict = pd.Series(my_extra_info.chr.values, index=my_extra_info.geneID).to_dict()
		my_strand_dict = pd.Series(my_extra_info.strand.values, index=my_extra_info.geneID).to_dict()
		#group by clusterID
		final_df = pd.DataFrame(columns=list(my_clusters_df.columns.values))
		my_grouped_clusters = my_clusters_df.groupby("clusterID")
		for name, group in my_grouped_clusters:
		  genes = list(group["geneID"])
		  genes_to_save = []
		  strands = [my_strand_dict[element] for element in genes]
		  chrs = [my_chr_dict[element] for element in genes]
		  for gene in genes:
		    if len([element for element in strands if element==my_strand_dict[gene]]) >= 2:
		      if len([element for element in chrs if element==my_chr_dict[gene]]) >= 2:
		        genes_to_save.append(gene)
		  if len(genes_to_save) >= 2:
		    new_group = group.loc[group.geneID.isin(genes_to_save)]
		    final_df = pd.concat([final_df, new_group])

		final_df.to_csv(str(output), sep="\t", header=False, index=False)


#select only those clusters where the genes on the same strand and chr are sequential
rule check_sequentiality:
	input:
		clusters = BROCCOLI+"/{my_version}/broken_genes/{species}/{species}-potentially_broken-step2.tab",
		coords = DATABASE+"/gene_extra_info/{species}_start_stop.tab",
		strand = DATABASE+"/gene_extra_info/{species}_chr_strand.tab"
	output:
		BROCCOLI+"/{my_version}/broken_genes/{species}/{species}-potentially_broken-step3.tab"
	run:

		import pandas as pd

		my_clusters = pd.read_table(str(input.clusters), sep="\t", header=None, names=["clusterID", "species", "geneID", "gene_name"])
		my_coords_df = pd.read_table(str(input.coords), sep="\t", header=None, names=["geneID", "chrs", "start", "stop"])
		my_strand_df = pd.read_table(str(input.strand), sep="\t", header=None, names=["geneID", "chrs", "strand"])
		#create a dictionary with key=gene, value=start
		my_start_dict = pd.Series(my_coords_df.start.values, index=my_coords_df.geneID).to_dict()
		my_chr_dict = pd.Series(my_coords_df.chrs.values, index=my_coords_df.geneID).to_dict()
		my_strand_dict = pd.Series(my_strand_df.strand.values, index=my_strand_df.geneID).to_dict()
		#create a dictionary with key=gene, value=stop
		my_stop_dict = pd.Series(my_coords_df.stop.values, index=my_coords_df.geneID).to_dict()
		#final_df = pd.DataFrame(columns=list(my_clusters.columns.values))
		final_df = pd.DataFrame(columns=["clusterID", "species", "chr:strand", "gene1", "gene1_comb", "gene2", "gene2_comb"])
		my_grouped_df = my_clusters.groupby("clusterID") #group by clusterID
		for name, group in my_grouped_df:
		  genes = list(group["geneID"])
		  chr_strand_dict = {element : (my_chr_dict[element], my_strand_dict[element]) for element in genes} #dictionary with key = geneID, value = (chr, strand)
		  for combination in list(set(list(chr_strand_dict.values()))):
		    my_genes = [gene for gene,comb in chr_strand_dict.items() if comb == combination]
		    #starts_list = [my_start_dict[element] for element in my_genes]
		    subsetted_start_dict = {key : my_start_dict[key] for key in my_genes}
		    ordered_genes = [key for (key, value) in sorted(subsetted_start_dict.items(), key=lambda x: x[1])]
		    all_starts = list(my_coords_df.loc[my_coords_df.chrs==my_chr_dict[ordered_genes[0]]]["start"])
		    #genes_to_save = []
		    for i in list(range(len(ordered_genes)-1)):
		      first_gene = ordered_genes[i]; first_gene_start=my_start_dict[first_gene]
		      second_gene = ordered_genes[i+1]; second_gene_start=my_start_dict[second_gene]
		      intermediate_starts = [element for element in all_starts if first_gene_start < element < second_gene_start]
		      if len(intermediate_starts) == 0:
		        final_entry = pd.DataFrame({"clusterID" : [name], "species" : [wildcards.species], "chr:strand" : [combination], "gene1" : [first_gene], "gene1_comb" : [chr_strand_dict[first_gene]], "gene2" : [second_gene], "gene2_comb" : [chr_strand_dict[second_gene]]})
		        final_df = pd.concat([final_df, final_entry])  
		#save to file
		final_df.to_csv(str(output), sep="\t", header=False, index=False, na_rep="NA")


#### Derive pairs of genes to align
#filter only for those clusters where there are exactly 2 or multiple broken genes (that depends on the gene_num wildcards)
#19/03/21: Modify the rule so that they work also without gene names
#19/03/21: I think the header is:
#1: ClusterID
#2: Species
#3: GeneID
#4: genename
rule filter_clusters_with_broken_genes:
	input:
		broken = BROCCOLI+"/{my_version}/broken_genes/{species}/{species}-potentially_broken-step3.tab",
		orthogroups = BROCCOLI+"/{my_version}/parsed_orthogroups.txt"
	output:
		step4 = BROCCOLI+"/{my_version}/broken_genes/{species}/{species}-potentially_broken-step4.tab",
		broken_pairs = BROCCOLI+"/{my_version}/broken_genes/{species}/{species}-broken_genes_pairs.tab"
	run:
		import pandas as pd
		from collections import Counter

		input_df = pd.read_table(str(input.broken), sep="\t", header=None, names=["clusterID", "species", "chr:strand", "gene1", "gene1_comb", "gene2", "gene2_comb"])
		parsed_orthogroups = pd.read_table(str(input.orthogroups), sep="\t", header=None, names=["clusterID", "species", "geneID", "genename"])
		geneID_clusterID_dict = pd.Series(parsed_orthogroups.clusterID.values, index=parsed_orthogroups.geneID).to_dict()
		geneID_genename_dict = pd.Series(parsed_orthogroups.genename.values, index=parsed_orthogroups.geneID).to_dict()
 
		cluster_gene_counts_dict = dict(Counter(list(input_df["clusterID"])))
		clusters_to_save = [element for element in list(cluster_gene_counts_dict.keys()) if cluster_gene_counts_dict[element] >= 1] #select all the genes broken in 2 or more pieces
		#list of clusters with only two or more broken genes within
		#if str(wildcards.gene_num) == "two_genes":
		  #clusters_to_save = [element for element in list(cluster_gene_counts_dict.keys()) if cluster_gene_counts_dict[element] == 1]
		#if str(wildcards.gene_num) == "more_genes":
		  #clusters_to_save = [element for element in list(cluster_gene_counts_dict.keys()) if cluster_gene_counts_dict[element] >= 2]
		#filter only for clusters with given number of broken genes
		final_df = input_df.loc[input_df.clusterID.isin(clusters_to_save)]
		final_df = final_df[["clusterID", "gene1", "gene2"]]
		final_df.to_csv(str(output.broken_pairs), sep="\t", na_rep="NA", index=False, header=False) #save to file
		#print the genes one by one
		all_genes = list(final_df["gene1"])+list(final_df["gene2"])
		single_genes_df = pd.DataFrame({"geneID" : all_genes})
		single_genes_df["species"] = wildcards.species
		single_genes_df["genename"] = single_genes_df["geneID"].map(geneID_genename_dict)
		single_genes_df["clusterID"] = list(single_genes_df["geneID"].map(geneID_clusterID_dict))
		single_genes_df = single_genes_df.loc[:,["clusterID", "species", "geneID", "genename"]]
		single_genes_df.to_csv(str(output.step4), sep="\t", header=False, index=False, na_rep="NA")

#I want a file with:
#1: ClusterID
#2: BrokenID 1
#3: humanID
#For all the combinations of broken genes and human ones. 
rule broken_human_genes_pairs:
	input:
		broken_genes = BROCCOLI+"/{my_version}/broken_genes/{species}/{species}-potentially_broken-step4.tab",
		clusters = BROCCOLI+"/{my_version}/parsed_orthogroups.txt"
	output:
		BROCCOLI+"/{my_version}/broken_genes/{species}/{species}-broken_human_pairs.tab"
	run:
		import pandas as pd
		import itertools

		broken_df = pd.read_table(str(input.broken_genes), sep="\t", header=None, names=["clusterID", "species", "geneID", "gene_name"])
		clusters_df = pd.read_table(str(input.clusters), sep="\t", header=None, names=["clusterID", "species", "geneID", "gene_name"])

		clusters_to_save = list(set(list(broken_df["clusterID"]))) #select interesting clusters
		#subset general clusters for the human genes in the interesting clusters
		filtered_clusters_df = clusters_df.loc[clusters_df.clusterID.isin(clusters_to_save) & clusters_df.species.isin(["Hs2"])]
		combined_df = pd.concat([broken_df, filtered_clusters_df])
		my_grouped_df = combined_df.groupby("clusterID") #group df by cluster ID
		final_df = pd.DataFrame(columns=["clusterID", "broken_gene", "human_gene"])
		for name, group in my_grouped_df: #cycle on each cluster
		  human_genes = list(group.loc[group.species=="Hs2"]["geneID"]) #list of the human genes in the cluster
		  broken_genes = list(group.loc[group.species==str(wildcards.species)]["geneID"])
		  #generate all possible combinations between the members of the two lists
		  all_combs = [(x,y) for x in broken_genes for y in human_genes]
		  for element in all_combs:
		    element_df = pd.DataFrame({"clusterID" : [name], "broken_gene" : [element[0]], "human_gene" : [element[1]]})
		    final_df = pd.concat([final_df, element_df])
		#save to file
		final_df.to_csv(str(output), sep="\t", index=False, header=False, na_rep="NA")


rule filter_longest_human_pairs:
	input:
		human_pairs = BROCCOLI+"/{my_version}/broken_genes/{species}/{species}-broken_human_pairs.tab",
		prot_length = DATABASE+"/gene_extra_info/Hs2_ref_proteins_lengths"
	output:
		BROCCOLI+"/{my_version}/broken_genes/{species}/{species}-longest_human_pairs.tab"
	run:
		import pandas as pd

		#read inputs
		gene_pairs_df = pd.read_table(str(input.human_pairs), sep="\t", header=None, names=["clusterID", "geneID", "hsa_geneID"])
		prot_len_df = pd.read_table(str(input.prot_length), sep="\t", header=None, names=["geneID", "prot_len"])
		#create dictionary {geneID : prot_len}
		prot_len_dict = pd.Series(prot_len_df.prot_len.values, index=prot_len_df.geneID)
		grouped_df = gene_pairs_df.groupby("clusterID")
		#generate final df
		final_df = pd.DataFrame(columns=list(gene_pairs_df.columns))
		#select the longest protein for each group (clusterID)
		for name, group	in grouped_df:
		  hsa_genes = list(set(list(group["hsa_geneID"])))
		  length_list = [prot_len_dict[element] for element in hsa_genes]
		  my_max = max(length_list) 
		  my_prot_len_dict = {key:prot_len_dict[key] for key in hsa_genes}
  		  longest_gene = [key for key in list(my_prot_len_dict.keys()) if my_prot_len_dict[key]==my_max][0]

		  group_df = group.loc[group.hsa_geneID==longest_gene]
		  #concatenate to final df
		  final_df = pd.concat([final_df, group_df])
		#save final_df to file
		final_df.to_csv(str(output), sep="\t", header=False, index=False, na_rep="NA")


#Here I select a set of control genes against which to select the cutoffs of similarity scores and overlap.
rule control_genes_pairs:
	input:
		clusters = BROCCOLI+"/{my_version}/parsed_orthogroups.txt",
		potentially_broken = BROCCOLI+"/{my_version}/broken_genes/{species}/{species}-potentially_broken-step4.tab"
	output:
		BROCCOLI+"/{my_version}/broken_genes/{species}/{species}-control_genes_pairs.tab"
	run:
		import pandas as pd

		clusters_df = pd.read_table(str(input.clusters), sep="\t", header=None, names=["clusterID", "species", "geneID", "gene_name"])
		PBG_df = pd.read_table(str(input.potentially_broken), sep="\t", header=None, names=["clusterID", "species", "geneID", "gene_name"])
		PBG_clusters = list(set(list(PBG_df["clusterID"]))) #select the PBG clusters
		#subset cluster df only for species
		species_clusters_df = clusters_df.loc[clusters_df.species==wildcards.species]
		#select the clusters where there are 2 genes per species.
		all_species_clusters = list(species_clusters_df["clusterID"])
		clusters_with_pairs = list(set([element for element in all_species_clusters if all_species_clusters.count(element) == 2]))
		no_PBG_clusters = [element for element in clusters_with_pairs if element not in PBG_clusters]
		final_species_clusters = species_clusters_df.loc[species_clusters_df.clusterID.isin(no_PBG_clusters)]
		#put the genes one next to the other
		final_df = pd.DataFrame(columns=["clusterID", "geneID_1", "geneID_2"])
		my_grouped_df = final_species_clusters.groupby("clusterID")
		for name, group in my_grouped_df:
		  my_geneID_1 = list(group["geneID"])[0]
		  my_geneID_2 = list(group["geneID"])[1]
		  group_df = pd.DataFrame({"clusterID" : [name], "geneID_1" : [my_geneID_1], "geneID_2" : [my_geneID_2]})
		  final_df = pd.concat([final_df, group_df])
		#save to file
		final_df.to_csv(str(output), sep="\t", header=False, index=False, na_rep="NA")

######### Alignments
rule perform_alignment:
	input:
		pairs = BROCCOLI+"/{my_version}/broken_genes/{species}/{species}-{category}_pairs.tab",
		fasta = EXINT_REF_DIR+"/{species}_ref_exint.fasta",
		fasta_hsa = EXINT_REF_DIR+"/Hs2_ref_exint.fasta"
	output:
		BROCCOLI+"/{my_version}/broken_genes/{species}/alignments_check_{category}.txt"
	params:
		out_dir = BROCCOLI+"/{my_version}/broken_genes/{species}/{category}"
	shell:
		"""
		if [[ ! -d {params.out_dir} ]]; then \
			mkdir {params.out_dir}; \
		fi; \
		TOT=$(cat {input.pairs} | wc -l); \
		for number in $(echo $(seq $TOT)); do \
			gene1=$(cat {input.pairs} | awk -v num=$number 'NR==num {{print $2}}'); \
			gene2=$(cat {input.pairs} | awk -v num=$number 'NR==num {{print $3}}'); \
			if [ {wildcards.category} == "longest_human" ]; then \
				{MY_MAFFT} --auto --quiet <(cat \
					<(grep -A1 -w $gene1 {input.fasta} | sed "s/>.*/>$gene1/") \
					<(grep -A1 -w $gene2 {input.fasta_hsa} | sed "s/>.*/>$gene2/")) \
			> {params.out_dir}/$gene1-$gene2.gde; else \
				{MY_MAFFT} --auto --quiet <(cat \
					<(grep -A1 -w $gene1 {input.fasta} | sed "s/>.*/>$gene1/") \
					<(grep -A1 -w $gene2 {input.fasta} | sed "s/>.*/>$gene2/")) \
			> {params.out_dir}/$gene1-$gene2.gde; fi; 
		done; \
		paste <(echo "alignments_performed") <(ls {params.out_dir} | wc -l) > {output}
		"""

#Here I will have a file for category: 
rule compute_similarity_scores:
	input:
		BROCCOLI+"/{my_version}/broken_genes/{species}/alignments_check_{category}.txt"
	output:
		BROCCOLI+"/{my_version}/broken_genes/{species}/{species}-{category}-similarity_scores.tab"
	params:
		input_dir = BROCCOLI+"/{my_version}/broken_genes/{species}/{category}"
	shell:
		"""
		for file in $(ls {params.input_dir}); do \
			perl {COMPUTE_SIM_SCORE} <(cat {params.input_dir}/$file | sed 's/>/%/'); done > {output}
		"""

rule compute_percentage_overlap:
	input:
		BROCCOLI+"/{my_version}/broken_genes/{species}/alignments_check_{category}.txt"
	output:
		BROCCOLI+"/{my_version}/broken_genes/{species}/{species}-{category}-overlap.tab"
	params:
		input_dir = BROCCOLI+"/{my_version}/broken_genes/{species}/{category}"
	shell:
		"""
		for file in $(ls {params.input_dir}); do \
			python {COMPUTE_PROT_OVERLAP} -i {params.input_dir}/$file; done > {output}
		"""

#This is only for the comparison with the longest human protein
rule compute_human_overlap:
	input:
		BROCCOLI+"/{my_version}/broken_genes/{species}/alignments_check_longest_human.txt"
	output:
		BROCCOLI+"/{my_version}/broken_genes/{species}/longest_human-interval_overlap.tab"
	params:
		input_dir = BROCCOLI+"/{my_version}/broken_genes/{species}/longest_human"
	conda:
		CONDA_ENVS+"/broccoli_1.2.yml"
	shell:
		"""
		for file in $(ls {params.input_dir}); do \
			python {TARGET_MATCH_PORTION} -i {params.input_dir}/$file; done > {output}
		"""	

#HEADER
#1 clusterID
#2 species
#3 geneID1
#4 geneID2
#5 protsim 1vs2
#6 protsim 2vs1
#7 overlap 1vs2
#8 overlap 2vs1

rule combine_information:
	input:
		broken_pairs = BROCCOLI+"/{my_version}/broken_genes/{species}/{species}-{category}_pairs.tab",
		sim_scores = BROCCOLI+"/{my_version}/broken_genes/{species}/{species}-{category}-similarity_scores.tab",
		overlap = BROCCOLI+"/{my_version}/broken_genes/{species}/{species}-{category}-overlap.tab"
	output:
		BROCCOLI+"/{my_version}/broken_genes/{species}/{species}-{category}-combined_info.tab"
	run:
		import pandas as pd

		#read input
		broken_input_df = pd.read_table(str(input.broken_pairs), sep="\t", header=None, names=["clusterID", "geneID1", "geneID2"])
		sim_scores_df = pd.read_table(str(input.sim_scores), sep="\t", header=None, names=["geneID1", "geneID2", "sim_score"])
		overlap_df = pd.read_table(str(input.overlap), sep="\t", header=None, names=["geneID1", "geneID2", "overlap"])
		#create dictionary with each of the genes first.
		sim_scores_df["sim_score"] = pd.Series([round(element, 4) for element in list(sim_scores_df["sim_score"])]) #round to 4 significant digits
		sim_scores_dict = pd.Series(sim_scores_df.sim_score.values, index=sim_scores_df.geneID1).to_dict() 
		overlap_df["overlap"] = pd.Series([round(element, 4) for element in list(overlap_df["overlap"])]) #round to 4 significant digits
		overlap_dict = pd.Series(overlap_df.overlap.values, index=overlap_df.geneID1).to_dict()
		#translate geneID1 and geneID2 with the respective sim_score/overlap from the same dict
		broken_input_df["geneID1_sim_score"] = broken_input_df["geneID1"].map(sim_scores_dict)
		broken_input_df["geneID2_sim_score"] = broken_input_df["geneID2"].map(sim_scores_dict)
		broken_input_df["geneID1_overlap"] = broken_input_df["geneID1"].map(overlap_dict)
		broken_input_df["geneID2_overlap"] = broken_input_df["geneID2"].map(overlap_dict)
		#add species
		broken_input_df["species"] = pd.Series([wildcards.species for element in list(range(broken_input_df.shape[0]))])
		#rearrange columns
		broken_input_df = broken_input_df[["clusterID", "species", "geneID1", "geneID2", "geneID1_sim_score", "geneID2_sim_score", "geneID1_overlap", "geneID2_overlap"]]
		#write to file
		broken_input_df.to_csv(str(output), sep="\t", index=False, header=True, na_rep="NA")

###### Combine info human comparison
rule combine_info_longest_human:
	input:
		broken_pairs = BROCCOLI+"/{my_version}/broken_genes/{species}/{species}-broken_genes_pairs.tab",
		longest_human = BROCCOLI+"/{my_version}/broken_genes/{species}/{species}-longest_human_pairs.tab",
                interval_overlap = BROCCOLI+"/{my_version}/broken_genes/{species}/longest_human-interval_overlap.tab" 
	output:
		BROCCOLI+"/{my_version}/broken_genes/{species}/{species}-longest_human-interval_overlap.tab"
	run:
		import pandas as pd

		broken_pairs_df = pd.read_table(str(input.broken_pairs), sep="\t", header=None, names=["clusterID", "geneID1", "geneID2"])
		longest_human_df = pd.read_table(str(input.longest_human), sep="\t", header=None, names=["clusterID", "geneID1", "geneID2"])
		intervals_df = pd.read_table(str(input.interval_overlap), sep="\t", header=None, names=["geneID", "hsa_geneID", "start", "stop", "interval", "protein_length"])

		#filter the broken_genes_df
		clusters_to_save = list(longest_human_df["clusterID"])
		broken_pairs_df = broken_pairs_df.loc[broken_pairs_df.clusterID.isin(clusters_to_save)]

		#create dictionaries to add information to the final df
		geneID_overlap_dict = pd.Series(intervals_df.interval.values, index=intervals_df.geneID).to_dict()
		geneID_start_dict = pd.Series(intervals_df.start.values, index=intervals_df.geneID).to_dict()
		geneID_stop_dict = pd.Series(intervals_df.stop.values, index=intervals_df.geneID).to_dict()
		#NB: this is the geneID of the other species but the length of the human protein as value
		protein_len_dict = pd.Series(intervals_df.protein_length.values, index=intervals_df.geneID).to_dict()
		geneID_hsa_gene = pd.Series(intervals_df.hsa_geneID.values, index=intervals_df.geneID).to_dict()

		broken_pairs_df["hsa_gene"] = broken_pairs_df["geneID1"].map(geneID_hsa_gene)
		broken_pairs_df["hsa_prot_len"] = broken_pairs_df["geneID1"].map(protein_len_dict)
		#these are the ones I'll print. I also need them separated because of stupid python
 		broken_pairs_df["geneID1_match"] = broken_pairs_df["geneID1"].map(geneID_overlap_dict)
		broken_pairs_df["geneID2_match"] = broken_pairs_df["geneID2"].map(geneID_overlap_dict)
		broken_pairs_df["geneID1_match_start"] = broken_pairs_df["geneID1"].map(geneID_start_dict)
		broken_pairs_df["geneID1_match_stop"] = broken_pairs_df["geneID1"].map(geneID_stop_dict)
		broken_pairs_df["geneID2_match_start"] = broken_pairs_df["geneID2"].map(geneID_start_dict)
		broken_pairs_df["geneID2_match_stop"] = broken_pairs_df["geneID2"].map(geneID_stop_dict)
		#I need to add this line because there are some chimeric genes (how shitty is that??) that end up in more clusters. But each gene ID can be repeated only once as a key.
		broken_pairs_df = broken_pairs_df.dropna()
		my_geneID1_match_list = [range(int(start), int(stop)) for start, stop in zip(list(broken_pairs_df["geneID1_match_start"]), list(broken_pairs_df["geneID1_match_stop"]))]
		my_geneID2_match_list = [range(int(start), int(stop)) for start, stop in zip(list(broken_pairs_df["geneID2_match_start"]), list(broken_pairs_df["geneID2_match_stop"]))]
		#compute the range overlap
		my_match_overlap = [range(max(my_geneID1_match_list[x][0], my_geneID2_match_list[x][0]), min(my_geneID1_match_list[x][-1], my_geneID2_match_list[x][-1])+1) for x in list(range(broken_pairs_df.shape[0]))]
		my_match_overlap_len = [len(element) for element in my_match_overlap]
			
		#add to final_df
		broken_pairs_df["match_overlap"] = my_match_overlap_len
		######## compute the match_overlap_proportion based on the shortest match (changed on 26/03/2021)
		broken_pairs_df["geneID1_match_length"] = broken_pairs_df["geneID1_match_stop"] - broken_pairs_df["geneID1_match_start"]
		broken_pairs_df["geneID2_match_length"] = broken_pairs_df["geneID2_match_stop"] - broken_pairs_df["geneID2_match_start"]
		broken_pairs_df["higher_match"] = [element[0] if float(element[0]) >= float(element[1]) else element[1] for element in list(zip(list(broken_pairs_df["geneID1_match_length"]), list(broken_pairs_df["geneID2_match_length"])))] 
		broken_pairs_df["match_overlap_proportion"] = broken_pairs_df["match_overlap"]/broken_pairs_df["higher_match"]
		#broken_pairs_df["match_overlap_proportion"] = broken_pairs_df["match_overlap"]/broken_pairs_df["hsa_prot_len"]
		##############
		final_df = broken_pairs_df.loc[:,["clusterID", "geneID1", "geneID2", "hsa_gene", "hsa_prot_len", "geneID1_match", "geneID2_match", "match_overlap", "match_overlap_proportion"]]
		#write final df to file
		final_df.to_csv(str(output), sep="\t", header=True, index=False, na_rep="NA")


#Header output:
#1	clusterID
#2	species
#3	geneID1
#4	geneID2
#5	longest_humanID
#5	geneID1_sim_score (geneID1 vs geneID2)
#6	geneID2_sim_score (geneID2 vs geneID1)
#7	matched proportion
rule join_broken_and_longest_human_info:
	input:
		broken_genes = BROCCOLI+"/{my_version}/broken_genes/{species}/{species}-broken_genes-combined_info.tab",
		longest_human = BROCCOLI+"/{my_version}/broken_genes/{species}/{species}-longest_human-interval_overlap.tab"
	output:
		BROCCOLI+"/{my_version}/broken_genes/{species}/{species}-ALL_combined_info_tofilter.tab"
	run:
		import pandas as pd

		broken_genes_df = pd.read_table(str(input.broken_genes), sep="\t", index_col=False, header=0)
		longest_human_df = pd.read_table(str(input.longest_human), sep="\t", index_col=False, header=0)
		#Create a dictionary with key=geneID1;geneID2, value=sim_score1;sim_score2
		broken_genes_df["gene_pairs"] = broken_genes_df["geneID1"]+";"+broken_genes_df["geneID2"]
		broken_genes_df["sim_scores"] = pd.Series([str(element) for element in list(broken_genes_df["geneID1_sim_score"])])+";"+pd.Series([str(element) for element in list(broken_genes_df["geneID2_sim_score"])])
		gene_pair_sim_score_dict = pd.Series(broken_genes_df.sim_scores.values, index=broken_genes_df.gene_pairs).to_dict()
		#Add columns with gene pair and sim scores to human longest df
		longest_human_df["gene_pairs"] = longest_human_df["geneID1"]+";"+longest_human_df["geneID2"]
		longest_human_df["sim_scores"] = longest_human_df["gene_pairs"].map(gene_pair_sim_score_dict)
		#separate sim scores
		longest_human_df["geneID1_sim_score"] = [element.split(";")[0] for element in list(longest_human_df["sim_scores"])]
		longest_human_df["geneID2_sim_score"] = [element.split(";")[1] for element in list(longest_human_df["sim_scores"])]
		#Select columns for final dataframe
		final_df = longest_human_df[["clusterID", "gene_pairs", "hsa_gene", "geneID1_sim_score", "geneID2_sim_score", "match_overlap_proportion"]]
		#Save df to file
		final_df.to_csv(str(output), sep="\t", index=False, header=True, na_rep="NA")	
	
#Header input: 
#1	clusterID
#2	species	
#3	geneID1
#4	geneID2
#5	geneID1_sim_score
#6	geneID2_sim_score
#7	geneID1_overlap
#8	geneID2_overlap

rule select_potentially_broken_genes:
	input:
		BROCCOLI+"/{my_version}/broken_genes/{species}/{species}-ALL_combined_info_tofilter.tab"
	output:
		BROCCOLI+"/{my_version}/broken_genes/{species}/{species}-ALL_combined_info_filtered.tab"
	shell:
		"""
		cat {input} | awk '($4<={SEQSIM_CUTOFF} || $5 <={SEQSIM_CUTOFF}) && $6<={HUMAN_MATCH_CUTOFF}' > {output}
		"""

rule join_potentially_broken_genes_by_species:
	input:
		BROCCOLI+"/{my_version}/broken_genes/{species}/{species}-ALL_combined_info_filtered.tab",
		#more_genes = BROCCOLI+"/{my_version}/broken_genes/more_genes/{species}-ALL_combined_info_filtered.tab"
	output:
		BROCCOLI+"/{my_version}/broken_genes/{species}-selected_broken_genes.tab"
	run:
		import pandas as pd

		#two_broken_df = pd.read_table(str(input.two_genes), sep="\t", index_col=False, header=None, names=["clusterID", "gene_pairs", "hsa_gene", "geneID1_sim_score", "geneID2_sim_score", "match_overlap_proportion"])
		more_broken_df = pd.read_table(str(input), sep="\t", index_col=False, header=None, names=["clusterID", "gene_pairs", "hsa_gene", "geneID1_sim_score", "geneID2_sim_score", "match_overlap_proportion"])
		#join genes on the "more" side
		more_broken_df["geneID1"] = [element.split(";")[0] for element in list(more_broken_df["gene_pairs"])]
		more_broken_df["geneID2"] = [element.split(";")[1] for element in list(more_broken_df["gene_pairs"])]	
		more_broken_grouped_df = more_broken_df.groupby("clusterID")
		final_df = pd.DataFrame()
		for name, group in more_broken_grouped_df:
		  if group.shape[0] >= 2:
		    group = group[["geneID1", "geneID2"]]
		    geneID1_list = list(group["geneID1"])
		    geneID2_list = list(group["geneID2"])
		    common_genes = [gene for gene in geneID1_list if gene in geneID2_list]
		    if len(common_genes) >= 1:
		      for gene in common_genes:
			#join the two lines
		        subset_group_all = pd.concat([group[group["geneID1"]==gene].reset_index(drop=True), group[group["geneID2"]==gene].reset_index(drop=True)], axis=1)
			all_genes = list(set(subset_group_all.values.tolist()[0]))
			final_group = pd.Series([all_genes[0]+";"+all_genes[1]+";"+all_genes[2]]).rename("gene_pairs")
			#final_group = pd.concat([final_group, subset_group])
		    else:
		      group["gene_pairs"] = group["geneID1"]+";"+group["geneID2"]
		      final_group = group["gene_pairs"]
		  else:
		      group["gene_pairs"] = group["geneID1"]+";"+group["geneID2"]
		      final_group = group["gene_pairs"]
		  final_df = pd.concat([final_df, final_group])
		#join more and two genes in the same dataframe
		#final_df = pd.concat([final_df, two_broken_df["gene_pairs"]])
		#save df to final file
		final_df.to_csv(str(output), sep="\t", index=False, header=False, na_rep="NA")



##############################################
########### CHIMERIC GENES  ###################
###############################################

#Header output
#1. clusterID
#2. species
#3. geneID
#4. label: CHIMERIC/NOT_CHIMERIC
#The chimeric genes are simply the ones which appear in more OGs.
rule isolate_chimeric_orthogroups:
	input:
		BROCCOLI+"/{my_version}/parsed_orthogroups.txt"
	output:
		chimeric_OG = BROCCOLI+"/{my_version}/chimeric_proteins/chimeric_orthogroups.tab",
		potentially_fused = BROCCOLI+"/{my_version}/chimeric_proteins/potentially_fused_orthogroups.tab"
	run:
		import pandas as pd
		import collections
		
		OG_df = pd.read_table(str(input), sep="\t", index_col=False, header=None, names=["OG_ID", "species", "geneID", "geneName"]) #read input.
		chimeric_genes = [element for element, my_count in collections.Counter(list(OG_df["geneID"])).items() if my_count >= 2] #isolate genes shared between two or more OGs.
		chimeric_OGs = list(OG_df[OG_df["geneID"].isin(chimeric_genes)]["OG_ID"]) #generate a list of OG_IDs containing the chimeric genes.
		chimeric_OGs_df = OG_df[OG_df["OG_ID"].isin(chimeric_OGs)] #filter the original df with those OG_IDs.
		chimeric_OGs_df["chimeric_label"] = ["chimeric" if element in chimeric_genes else "not_chimeric" for element in list(chimeric_OGs_df["geneID"])] #add chimeric gene label.
		#isolate OGs with chimeric genes coming from more than one species.
		chimeric_OGs_list = list(chimeric_OGs_df[chimeric_OGs_df["chimeric_label"]=="chimeric"][["OG_ID", "species"]].drop_duplicates()["OG_ID"])
		pot_fused_OG_list = [element for element, my_count in collections.Counter(chimeric_OGs_list).items() if my_count >=2] #In the same OG, there are chimeric genes from at least two species.
		#The genes from the different species have to be shared between the same OGs.
		pot_fused_chimeric_genes_df = chimeric_OGs_df[(chimeric_OGs_df["chimeric_label"]=="chimeric") & (chimeric_OGs_df["OG_ID"].isin(pot_fused_OG_list))]
		grouped_df = pot_fused_chimeric_genes_df.groupby("geneID")
		chimeric_gene_OG_dict = {}
		for gene, group in grouped_df:
		  chimeric_gene_OG_dict[gene] = tuple(sorted(list(group["OG_ID"])))
		duplicated_OGs_full = [list(element) for element, my_count in collections.Counter(list(chimeric_gene_OG_dict.values())).items() if my_count >=2] #these are the OG containing the exact same chimeric genes from more species
		duplicated_OGs_flatten = [OG_ID for element in duplicated_OGs_full for OG_ID in element]
		final_chimeric_OGs_df = chimeric_OGs_df[~(chimeric_OGs_df["OG_ID"].isin(duplicated_OGs_flatten))]
		final_pot_fused_chimeric_OGs_df = chimeric_OGs_df[chimeric_OGs_df["OG_ID"].isin(duplicated_OGs_flatten)]
		#save to output file
		final_chimeric_OGs_df.to_csv(str(output.chimeric_OG), sep="\t", index=False, header=True, na_rep="NA")
		final_pot_fused_chimeric_OGs_df.to_csv(str(output.potentially_fused), sep="\t", index=False, header=True, na_rep="NA")


#CHIMERIC_GENES has to be modified so that it generated batches of 50 genes.

#Generate the multiple alignments within the clusters containing each chimeric gene
#Input header: OG_ID, species, geneID, geneName, chimeric_label

rule generate_multiple_alignments:
	input:
		chimeric_OG = BROCCOLI+"/{my_version}/chimeric_proteins/chimeric_orthogroups.tab",
		fastas = expand("{path}/{{my_version}}/fastas/{species}_ref_exint.fasta", path=BROCCOLI, species=ALL_SPECIES)
	output:
		BROCCOLI+"/{my_version}/chimeric_proteins/multiple_aln/batch_{batch_index}.log"
	params:
		fastas_dir = BROCCOLI+"/{my_version}/fastas",
		chimeric_genes = lambda wildcards: str(CHIMERIC_GENES[int(wildcards.batch_index)]),
		output_dir = BROCCOLI+"/{my_version}/chimeric_proteins/multiple_aln"
	conda:
		CONDA_ENVS+"/broccoli_1.2.yml"
	shell:
		"""
		python {ALIGN_CHIMERIC_OG} --input_fasta {params.fastas_dir} --input_OG {input.chimeric_OG} --chimeric_genes {params.chimeric_genes} --mafft {MY_MAFFT} --output {params.output_dir}; \
		echo -e "Performed multiple alignments for the orthogroups of the following chimeric genes:\n{params.chimeric_genes}" > {output}
		"""	

#I need to extract the portion of the chimeric gene which aligns with the other genes in the orthogroup
#NB: for all the orthogroups in which a chimeric gene is contained.
#Header of the potential output:
#1. chimeric geneID
#2. orthogroupID
#3. first AA in the chimeric gene aligned with at least 20% of the other genes in the orthogroup.
#4. last AA in the chimetic gene aligned with at least 20% of the other genes in the orthogroup.
#5. Exon num of the chimeric gene in which the first aligned AA falls.
#6. Exon num of the chimeric gene in which the last aligned AA falls.
rule extract_aligned_fragments:
	input:
		expand("{path}/{my_version}/chimeric_proteins/multiple_aln/batch_{batch_index}.log", path=BROCCOLI, my_version=MY_VERSION, batch_index=CHIMERIC_GENES_BATCHES)
	output:
		BROCCOLI+"/{my_version}/chimeric_proteins/aligned_fragments_info.tab"
	params:
		input_dir = BROCCOLI+"/{my_version}/chimeric_proteins/multiple_aln",
		exon_position_dir = DATABASE+"/aa_position" 
	shell:
		"""
		echo $(ls {params.input_dir}/*-multiple_aln | xargs -n1 basename) | sed 's/-multiple_aln//g; s/ /;/g' > {output}.tmp; \
		python {GET_CHIMERIC_ALIGNED_REGION} 	--input_dir {params.input_dir} \
							--exon_positions_dir {params.exon_position_dir} \
							--alignment {output}.tmp \
							--overlap_stringency {OVERLAP_STRINGENCY} \
							--output {output};
		rm {output}.tmp
		"""		


###############################################
########### CHIMERIC GENES OLD ################
###############################################
#preliminary files
#Get files with AA positions for each species
rule geneID_refproteinID:
	input:
		GTF_ref = GTF_REF_DIR+"/{species}_annot-B.gtf"
	output:
		DATABASE+"/ref_prot_info/{species}_gene_ref_prot_dict"
	run:
		import pandas as pd
		import re

		my_gtf = pd.read_table(str(input), sep="\t", header=None)
		my_gtf_subset = my_gtf.iloc[:,my_gtf.shape[1]-1]
		#filter only the lines containing prot ID
		my_gtf_subset = my_gtf_subset[my_gtf_subset.str.contains("protein_id")]  
		#get gene ids list
		my_raw_gene_id = [part for element in list(my_gtf_subset) for part in element.split(";") if "gene_id" in part]
		my_gene_id = [re.sub(".*[ ]", "", re.sub('"', "", element)) for element in my_raw_gene_id]
		#get protein id list
		my_raw_prot_id = [part for element in list(my_gtf_subset) for part in element.split(";") if "protein_id" in part]
		my_prot_id = [re.sub(".*[ ]", "", re.sub('"', "", element)) for element in my_raw_prot_id]
		final_df = pd.concat([pd.Series(my_gene_id), pd.Series(my_prot_id)], axis=1)
		final_df = final_df.drop_duplicates()
		final_df.to_csv(str(output), sep="\t", header=False, index=False)

rule aa_position:
	input:
		gtf = GTF_REF_DIR+"/{species}_annot-B.gtf",
		ref_proteins = DATABASE+"/ref_prot_info/{species}_gene_ref_prot_dict"		
	output:
		DATABASE+"/aa_position/{species}_refprots_exons_pos.tab"
	params:
		out_dir = DATABASE+"/aa_position"
	shell:
		"""
		mkdir -p {params.out_dir}; \
		perl {GET_AA_POSITIONS} -GTF {input.gtf} -i {input.ref_proteins} -out {output}
		"""

###### Keep the chimeric proteins only in the cluster with which it gets a higher similarity score in the multiple alignment.
rule get_chimeric_clusters:
	input:
		BROCCOLI+"/{my_version}/parsed_orthogroups.txt"
	output:
		BROCCOLI+"/{my_version}/chimeric_proteins/Chimeric_clusters.tab"
	shell:
		"""
		perl {GET_CHIMERIC_CLUSTERS} {input} > {output}
		"""

##divide chimeric clusters in groups of 10
##the last argument is a directory
rule divide_chimeric_clusters:
	input:
		BROCCOLI+"/{my_version}/chimeric_proteins/Chimeric_clusters.tab"
	output:
		BROCCOLI+"/{my_version}/chimeric_proteins/splitted_clusters/part_1_clusters.txt"
	params:
		out_dir = BROCCOLI+"/{my_version}/chimeric_proteins/splitted_clusters"
	shell:
		"""
		perl {SPLIT_CLUSTERS} {input} 10 {params.out_dir}
		"""

##Get the scores for the chimeric proteins.
##see ALL_CLUSTERS_PART variable (this will have to change)
#ALL_CLUSTERS_PART=glob.wildcards(BROCCOLI+"/{my_version}/chimeric_proteins/splitted_clusters/part_*_clusters.txt")
ALL_CLUSTERS_PART = list(range(1,5))
#The exint ref dir really has to change
rule chimeric_protein_sim_scores:
	input:
		part_file = BROCCOLI+"/{my_version}/chimeric_proteins/splitted_clusters/part_{part}_clusters.txt",
		#ref_exint_dir = BROCCOLI+"/proteins_fasta/exint/ref"
	output:
		BROCCOLI+"/{my_version}/chimeric_proteins/sim_scores/scores_part_{part}.txt"
	params:
		out_dir = BROCCOLI+"/{my_version}/chimeric_proteins/sim_scores"
	shell:
		"""
		cd {params.out_dir}; \
		perl {GET_SIM_SCORES_CHIMERIC} {input.part_file} {EXINT_REF_DIR} {wildcards.part} {output}
		"""

##join all the scores generated for each part
rule join_scores:
	input:
		expand("{path}/{my_version}/chimeric_proteins/sim_scores/scores_part_{part}.txt", path=BROCCOLI, my_version=MY_VERSION, part=ALL_CLUSTERS_PART)
	output:
		BROCCOLI+"/{my_version}/chimeric_proteins/sim_scores/All_scores_chimeric_prots.tab"
	shell:
		"""
		cat {input} | sort -k2,2 > {output}
		"""

##Get the longest fragment of aligned aa
rule get_longest_fragment:
	input:
		chimeric_clusters = BROCCOLI+"/{my_version}/chimeric_proteins/Chimeric_clusters.tab",
		scores = BROCCOLI+"/{my_version}/chimeric_proteins/sim_scores/All_scores_chimeric_prots.tab"
	output:
		BROCCOLI+"/{my_version}/chimeric_proteins/Longest_aln_chimeric_prots.tab"
	shell:
		"""
		perl {GET_LONGEST_ALN} {input.chimeric_clusters} {input.scores} {output}
		"""

##Getting the position in the alignment of the exons of the chimeric genes
rule exons_pos_aln:
	input:
		all_pos = expand("{path}/aa_position/{species}_refprots_exons_pos.tab", path=DATABASE, species=ALL_SPECIES),
		chimeric_clusters = BROCCOLI+"/{my_version}/chimeric_proteins/Chimeric_clusters.tab",
		longest_fg = BROCCOLI+"/{my_version}/chimeric_proteins/Longest_aln_chimeric_prots.tab"
	output:
		BROCCOLI+"/{my_version}/chimeric_proteins/Exon_pos_in_aln.tab"
	params:
		aa_pos_dir = DATABASE+"/aa_position/" #ugly as hell, it will have to change
	shell:
		"""
		perl {GET_EXON_POS_ALN} {params.aa_pos_dir} {input.chimeric_clusters} {input.longest_fg} {output}
		"""

##Getting first and last exons of each fragments
rule first_last_exon_in_fg:
	input:
		BROCCOLI+"/{my_version}/chimeric_proteins/Exon_pos_in_aln.tab"
	output:
		BROCCOLI+"/{my_version}/chimeric_proteins/Exon_first-last_in_aln.tab"
	shell:
		"""
		perl {GET_FIRST_LAST_EX_ALN} {input} {output}
		"""

##Putting together all the fragments for each chimeric genes and getting the exon coords
rule combine_exon_pos_info:
	input:
		BROCCOLI+"/{my_version}/chimeric_proteins/Exon_first-last_in_aln.tab"
	output:
		BROCCOLI+"/{my_version}/chimeric_proteins/Combines_exons_pos_info.tab"
	shell:
		"""
		perl {GET_EXCOORDS} {input} {output}
		"""

##Getting the final fragments for each chimeric gene
rule final_info_chimeric_genes:
	input:
		chimeric_clusters = BROCCOLI+"/{my_version}/chimeric_proteins/Chimeric_clusters.tab",
		combined_pos = BROCCOLI+"/{my_version}/chimeric_proteins/Combines_exons_pos_info.tab",
		first_last = BROCCOLI+"/{my_version}/chimeric_proteins/Exon_first-last_in_aln.tab"
	output:
		main = BROCCOLI+"/{my_version}/chimeric_proteins/Final_fragments_chim_genes.tab",
		stats = BROCCOLI+"/{my_version}/chimeric_proteins/Final_fragments_chim_genes_stats.txt"
	shell:
		"""
		perl {GET_EX_PATH} {input.chimeric_clusters} {input.combined_pos} {input.first_last} {output.main} > {output.stats}
		"""

##############################################
############ Correct gtf #####################
##############################################
#Correct the gtf taking into account the broken and the chimeric genes

